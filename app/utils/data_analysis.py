from collections import Counter
from datetime import datetime
import re
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageDraw
from pyecharts.charts import Map
from pyecharts import options as opts


# 文本数据清洗
def remove_tags_emojis(text):
    # 定义 HTML 和 表情 标签的正则表达式
    pattern = re.compile(r'<[^>]+>|\[[^\]]+\]')

    # 使用 sub 函数将 HTML 标签替换为空字符串
    text = pattern.sub('', text)

    return text


# 云图绘制
def create_wordcloud(text):
    stopwords = [line.rstrip() for line in open('app/utils/lib/stopwords.txt', 'r', encoding='utf-8')]
    seq_list = list(jieba.cut(text, cut_all=False))
    # # 统计词频
    # word_freq = {}
    # for word in seq_list:
    #     if word not in stopwords:
    #         word_freq[word] = word_freq.get(word, 0) + 1
    #
    # # 按词频排序，取前100个
    # sorted_word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:100]

    font = 'C:/Windows/Fonts/STSong.ttf'

    # mask = np.array(Image.open("C:\heart.png"))
    wc = WordCloud(
        scale=10,  # 调整图片大小---（如果设置太小图会很模糊）
        font_path=font,  # 使用的字体库
        max_words=70,  # 词云显示的最大词数
        margin=2,  # 字体之间的间距
        # mask=mask,  # 背景图片
        background_color='white',  # 背景颜色
        max_font_size=200,
        # min_font_size=1,
        stopwords=stopwords,  # 屏蔽的内容
        collocations=False,  # 避免重复单词
        width=500, height=500  # 图像宽高，字间距
    )

    wc.generate_from_text(' '.join(seq_list))  # 制作词云
    wc.to_file('trash/wordcloud.jpg')  # 保存到当地文件

    # # 图片展示
    # plt.figure(dpi=100)  # 通过这里可以放大或缩小
    # plt.imshow(wc, interpolation='catrom')
    # plt.axis('off')
    # # plt.show()
    # plt.savefig('wordcloud.png', dpi=300, bbox_inches='tight')


def create_city_hot(data):
    province_map = {'北京': '北京市', '天津': '天津市', '河北': '河北省', '山西': '山西省',
                    '内蒙古': '内蒙古自治区',
                    '辽宁': '辽宁省', '吉林': '吉林省', '黑龙江': '黑龙江省', '上海': '上海市',
                    '江苏': '江苏省',
                    '浙江': '浙江省', '安徽': '安徽省', '福建': '福建省', '江西': '江西省',
                    '山东': '山东省',
                    '河南': '河南省', '湖北': '湖北省', '湖南': '湖南省', '广东': '广东省',
                    '广西': '广西壮族自治区',
                    '海南': '海南省', '重庆': '重庆市', '四川': '四川省', '贵州': '贵州省',
                    '云南': '云南省',
                    '西藏': '西藏自治区', '陕西': '陕西省', '甘肃': '甘肃省', '青海': '青海省',
                    '宁夏': '宁夏回族自治区',
                    '新疆': '新疆维吾尔自治区', '中国台湾': '台湾省', '中国香港': '香港特别行政区',
                    '中国澳门': '澳门特别行政区'}
    hot_map = {}
    print(data)
    if data == {}:
        return "ip为空"
    for key, value in data.items():
        if key in province_map:
            hot_map.update({province_map[key]: data[key]})
        else:
            hot_map[key] = value
    # 定义地理坐标系，将地图设置为中国
    map_1 = (
        Map(init_opts=opts.InitOpts(width="1400px",height='600px'))
        .add("", [list(z) for z in zip(list(hot_map.keys()), list(hot_map.values()))], "china")  # world 世界 china 中国
        .set_global_opts(
            title_opts=opts.TitleOpts(title="城市热力图"),
            visualmap_opts=opts.VisualMapOpts(max_=80),
        )
    )

    # 将生成的热力图保存为 HTML 文件
    map_1.render("trash/city_heat_map.html")


def time_line_analysis(time_line):

    dates = [datetime.strptime(t, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d') for t in time_line]  # 提取日期信息
    hours = [datetime.strptime(t, '%Y-%m-%d %H:%M:%S').strftime('%H') for t in time_line]  # 提取小时信息

    # 统计每个日期或小时出现的次数，并将结果转换为字典
    date_count = dict(Counter(dates))
    hour_count = dict(Counter(hours))

    # 绘制条形统计图
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
    fig.set_size_inches(12, 6)
    ax1.bar(date_count.keys(), date_count.values())
    ax1.set_xlabel('Date')
    ax1.set_ylabel('Count')
    ax1.set_title('Date Frequency')
    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=35)
    ax2.bar(hour_count.keys(), hour_count.values())
    ax2.set_xlabel('Hour')
    ax2.set_ylabel('Count')
    ax2.set_title('Hour Frequency')
    plt.xticks(rotation=45)
    plt.subplots_adjust(bottom=0.15)
    # plt.show()
    fig.set_size_inches(4, 4)
    plt.savefig('trash/time_line_analysis.png', dpi=100, bbox_inches='tight')
    # pass

def gender_analysis(data):
    # counts =
    fig, ax = plt.subplots()
    counts = data
    labels = list(counts.keys())
    values = list(counts.values())

    plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90)
    plt.axis('equal')
    plt.title('Gender Distribution')
    # plt.show()
    fig.set_size_inches(4, 4)
    plt.savefig('trash/gender_analysis.png', dpi=100, bbox_inches='tight')


if __name__ == '__main__':
    create_wordcloud()
    create_city_hot(data= {
    '福建': 4,
    '北京': 6,
    '日本': 1,
    '湖北': 5,
    '上海': 4,
    '广东': 12,
    '陕西': 3,
    '辽宁': 5,
    '宁夏': 1,
    '江苏': 5,
    '河南': 3,
    '甘肃': 2,
    '美国': 1,
    '英国': 1,
    '广西': 1,
    '浙江': 3,
    '安徽': 2,
    '山东': 6,
    '天津': 2,
    '': 1,
    '重庆': 1,
    '黑龙江': 1,
    '贵州': 1,
    '湖南': 2,
    '吉林': 1,
    '云南': 1,
    '中国台湾': 1,
    '山西': 1,
    '河北': 1
  })
    gender_analysis(data={
    'male': 44,
    'female': 34
  })
    time_line_analysis(time_line=[
    '2022-08-25 18:28:45',
    '2022-08-25 18:32:41',
    '2022-08-25 18:23:49',
    '2022-08-25 18:32:54',
    '2022-08-25 18:24:01',
    '2022-08-25 18:32:45',
    '2022-08-25 18:30:01',
    '2022-08-25 18:27:46',
    '2022-08-25 18:30:47',
    '2022-08-25 18:24:47',
    '2022-08-25 18:24:04',
    '2022-08-25 18:28:50',
    '2022-08-25 18:31:23',
    '2022-08-25 18:33:02',
    '2022-08-25 18:53:44',
    '2022-08-25 18:34:46',
    '2022-08-25 18:23:46',
    '2022-08-25 18:30:18',
    '2022-08-25 19:47:43',
    '2022-08-25 18:40:01',
    '2022-08-25 18:29:26',
    '2022-08-25 18:32:14',
    '2022-08-25 18:30:47',
    '2022-08-25 18:33:54',
    '2022-08-25 18:35:42',
    '2022-08-25 18:39:21',
    '2022-08-25 18:31:00',
    '2022-08-25 18:46:39',
    '2022-08-25 18:26:10',
    '2022-08-25 18:36:51',
    '2022-08-25 18:40:00',
    '2022-08-25 18:36:46',
    '2022-08-25 18:35:50',
    '2022-08-25 18:30:57',
    '2022-08-25 18:40:29',
    '2022-08-25 18:37:29',
    '2022-08-25 18:32:28',
    '2022-08-25 18:27:17',
    '2022-08-25 18:48:45',
    '2022-08-25 18:26:36',
    '2022-08-25 18:29:37',
    '2022-08-25 18:34:49',
    '2022-08-25 18:25:24',
    '2022-08-25 18:33:23',
    '2022-08-25 18:38:52',
    '2022-08-25 18:37:51',
    '2022-08-25 18:40:26',
    '2022-08-25 18:24:42',
    '2022-08-25 18:36:37',
    '2022-08-25 18:30:00',
    '2022-08-25 18:38:24',
    '2022-08-25 18:24:16',
    '2022-08-25 18:24:47',
    '2022-08-25 18:37:53',
    '2022-08-25 19:00:34',
    '2022-08-25 18:58:53',
    '2022-08-25 18:36:23',
    '2022-08-25 18:25:48',
    '2022-08-25 18:24:39',
    '2022-08-25 18:33:44',
    '2022-08-25 18:28:57',
    '2022-08-25 18:39:10',
    '2022-08-25 18:39:59',
    '2022-08-25 18:24:35',
    '2022-08-25 18:59:29',
    '2022-08-25 18:56:29',
    '2022-08-25 21:42:41',
    '2022-08-25 18:33:16',
    '2022-08-25 18:26:02',
    '2022-08-25 18:36:37',
    '2022-08-25 18:26:38',
    '2022-08-25 19:10:55',
    '2022-08-25 18:53:52',
    '2022-08-25 19:04:30',
    '2022-08-25 18:27:00',
    '2022-08-25 18:23:45',
    '2022-08-25 18:34:46',
    '2022-08-25 18:40:37',
    '2022-08-25 18:32:10',
    '2022-08-25 18:42:16',
    '2022-08-25 18:46:16',
    '2022-08-25 18:33:11',
    '2022-08-25 19:01:37',
    '2022-08-25 18:28:40',
    '2022-08-25 18:45:17',
    '2022-08-25 18:31:34',
    '2022-08-25 18:27:16',
    '2022-08-25 18:38:59',
    '2022-08-25 18:24:57',
    '2022-08-25 18:32:48',
    '2022-08-25 18:45:57',
    '2022-08-25 18:52:03',
    '2022-08-25 18:25:59',
    '2022-08-25 19:00:38',
    '2022-08-25 18:25:14',
    '2022-08-25 18:30:07',
    '2022-08-25 19:38:16',
    '2022-08-25 18:28:25',
    '2022-08-25 18:52:07',
    '2022-08-25 18:24:25',
    '2022-08-25 20:52:22',
    '2022-08-25 19:09:50',
    '2022-08-25 18:36:55',
    '2022-08-25 19:51:41',
    '2022-08-25 19:02:23',
    '2022-08-25 18:43:41',
    '2022-08-25 20:09:39',
    '2022-08-25 19:17:02',
    '2022-08-25 18:48:36',
    '2022-08-25 18:23:55',
    '2022-08-25 19:21:08',
    '2022-08-25 19:01:20',
    '2022-08-25 21:01:50',
    '2022-08-25 18:53:09',
    '2022-08-25 19:00:41',
    '2022-08-25 18:33:32',
    '2022-08-25 18:25:37',
    '2022-08-25 21:42:09',
    '2022-08-25 18:35:28',
    '2022-08-25 18:33:49',
    '2022-08-25 19:10:34',
    '2022-08-25 18:36:17',
    '2022-08-25 18:42:23',
    '2022-08-25 19:54:38',
    '2022-08-25 19:29:47',
    '2022-08-26 00:07:26',
    '2022-08-25 18:28:19',
    '2022-08-25 20:10:32',
    '2022-08-25 19:24:23',
    '2022-08-25 21:39:42',
    '2022-08-25 18:28:43',
    '2022-08-25 22:16:02',
    '2022-08-25 19:15:57',
    '2022-08-25 18:50:59',
    '2022-08-25 18:42:27',
    '2022-08-25 18:42:02',
    '2022-08-25 18:36:29',
    '2022-08-25 18:24:54',
    '2022-08-25 19:49:55',
    '2022-08-25 18:43:50',
    '2022-08-25 18:36:06',
    '2022-08-25 19:10:50',
    '2022-08-25 18:27:44',
    '2022-08-25 19:08:53',
    '2022-08-25 18:46:54',
    '2022-08-26 09:45:44',
    '2022-08-25 20:05:17',
    '2022-08-25 19:55:05',
    '2022-08-25 21:01:08',
    '2022-08-25 19:01:07',
    '2022-08-25 19:12:00',
    '2022-08-25 18:43:28',
    '2022-08-25 19:13:35',
    '2022-08-25 19:09:43',
    '2022-08-25 21:51:13',
    '2022-08-25 18:46:52',
    '2022-08-25 18:24:36',
    '2022-08-25 19:41:30',
    '2022-08-25 18:28:25',
    '2022-08-25 19:58:16',
    '2022-08-25 20:21:17',
    '2022-08-25 18:38:05',
    '2022-08-25 18:26:19',
    '2022-08-25 18:23:56',
    '2022-08-26 10:35:57',
    '2022-08-25 20:01:09',
    '2022-08-25 19:23:14',
    '2022-08-26 00:24:05',
    '2022-08-25 19:05:07',
    '2022-08-25 19:21:29',
    '2022-08-25 22:14:30',
    '2022-08-25 18:51:29',
    '2022-08-25 18:27:44',
    '2022-08-25 19:15:15',
    '2022-08-25 21:19:13',
    '2022-08-25 18:24:58',
    '2022-08-25 20:56:46',
    '2022-08-25 19:56:18',
    '2022-08-25 19:17:16',
    '2022-08-25 18:35:25',
    '2022-08-25 18:54:28',
    '2022-08-25 18:51:48',
    '2022-08-25 18:28:45',
    '2022-08-25 22:20:18',
    '2022-08-25 18:33:37',
    '2022-08-25 18:27:59',
    '2022-08-26 09:17:13',
    '2022-08-25 21:54:58',
    '2022-08-25 18:25:14',
    '2022-08-25 18:53:04',
    '2022-08-25 18:40:01',
    '2022-08-25 18:25:05',
    '2022-08-25 21:37:30',
    '2022-08-25 18:31:05',
    '2022-08-25 18:26:11',
    '2022-08-25 20:06:34',
    '2022-08-25 18:28:37',
    '2022-08-25 21:19:18',
    '2022-08-25 18:55:14',
    '2022-08-25 18:38:17',
    '2022-08-25 18:33:10',
    '2022-08-25 22:29:55',
    '2022-08-25 20:50:35',
    '2022-08-26 08:04:35',
    '2022-08-25 21:24:02',
    '2022-08-25 19:30:16',
    '2022-08-25 18:55:10',
    '2022-08-25 18:35:34',
    '2022-08-25 20:04:01',
    '2022-08-25 18:45:34',
    '2022-08-26 11:09:44',
    '2022-08-25 22:25:24',
    '2022-08-25 19:36:47',
    '2022-08-25 18:42:06',
    '2022-08-26 09:24:05',
    '2022-08-25 21:58:04',
    '2022-08-25 19:47:19',
    '2022-08-25 19:33:11',
    '2022-08-25 18:42:33',
    '2022-08-25 18:27:05',
    '2022-08-26 06:59:26',
    '2022-08-25 18:32:29',
    '2022-08-25 22:32:51',
    '2022-08-25 20:47:53',
    '2022-08-25 23:29:31',
    '2022-08-25 22:45:30',
    '2022-08-25 18:47:07',
    '2022-08-26 10:44:51',
    '2022-08-25 18:41:16',
    '2022-08-25 18:32:07',
    '2022-08-25 23:34:02',
    '2022-08-26 18:44:53',
    '2022-08-25 23:16:57',
    '2022-08-25 20:37:18',
    '2022-08-25 18:44:52',
    '2022-08-25 18:25:17',
    '2022-08-25 20:20:11',
    '2022-08-25 20:08:10',
    '2022-08-25 19:15:14',
    '2022-08-25 20:33:06',
    '2022-08-25 20:27:56',
    '2022-08-25 19:30:59',
    '2022-08-25 18:43:32',
    '2022-08-25 18:33:02',
    '2022-08-25 18:28:30',
    '2022-08-25 18:23:47',
    '2022-08-26 02:54:45',
    '2022-08-25 23:20:53',
    '2022-08-25 18:25:01',
    '2022-08-25 23:54:33',
    '2022-08-25 18:38:21',
    '2022-08-25 18:34:41',
    '2022-08-25 21:09:57',
    '2022-08-25 20:20:30',
    '2022-08-25 19:04:36',
    '2022-08-25 18:55:46',
    '2022-08-25 18:50:19',
    '2022-08-25 18:27:03',
    '2022-08-25 18:33:14',
    '2022-08-26 11:59:11',
    '2022-08-26 10:01:53',
    '2022-08-25 23:32:01',
    '2022-08-25 20:48:47',
    '2022-08-25 20:29:45',
    '2022-08-25 20:17:09',
    '2022-08-25 20:15:09',
    '2022-08-25 19:14:41',
    '2022-08-25 18:59:38',
    '2022-08-25 18:40:31',
    '2022-08-25 18:38:41',
    '2022-08-25 18:36:05',
    '2023-01-11 10:16:43',
    '2023-01-07 23:48:30',
    '2023-01-07 14:53:45',
    '2023-01-07 04:35:56',
    '2023-01-06 14:31:40',
    '2023-01-06 07:44:51',
    '2023-01-06 07:43:36',
    '2023-01-06 07:17:42',
    '2023-01-05 22:15:42',
    '2023-01-04 22:39:56',
    '2023-01-04 21:10:06',
    '2023-01-03 23:15:15',
    '2023-01-03 19:04:44',
    '2023-01-03 14:27:30',
    '2023-01-02 19:21:13',
    '2023-01-02 10:25:28'
  ])
    # # 将字符串转换为 datetime 对象并按照日期进行分类：
    # day_dict = {}
    # for time_str in time_line:
    #     time_obj = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
    #     day_str = time_obj.strftime('%Y-%m-%d')
    #     if day_str not in day_dict:
    #         day_dict[day_str] = []
    #     day_dict[day_str].append(time_obj)
    #
    # # 打印按日期分类的结果：
    # for day in day_dict:
    #     print(day + ': ' + str(day_dict[day]))
    #
    # # 将字符串转换为 datetime 对象并按照小时进行分类：
    # hour_dict = {}
    # for time_str in time_line:
    #     time_obj = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
    #     hour_str = time_obj.strftime('%Y-%m-%d %H')
    #     if hour_str not in hour_dict:
    #         hour_dict[hour_str] = []
    #     hour_dict[hour_str].append(time_obj)
    #
    # # 打印按小时分类的结果：
    # for hour in hour_dict:
    #     print(hour + ': ' + str(hour_dict[hour]))
    # 转换为datetime类型，并提取出日期或小时信息
    # # 作图
    # c = (
    #     Map(init_opts=opts.InitOpts(width="1400px",height='600px'))  # 图表大小
    #     # 添加数据系列名称, 数据(list格式), 地图名称, 不显示小红点
    #     .add("", [list(z) for z in zip(data['国家_re'], data['GDP(亿美元)'])], "world",is_map_symbol_show=False)
    #     .set_series_opts(label_opts=opts.LabelOpts(is_show=False))  # 标签不显示(国家名称不显示)
    #     .set_global_opts(
    #         title_opts=opts.TitleOpts(title="2020年GDP前20国家",subtitle='单位: 亿美元'),   # 主标题与副标题名称
    #         visualmap_opts=opts.VisualMapOpts(max_=50000),               # 值映射最大值
    #     )
    # )
    # c.render("2020年GDP前20国家.html")       # 生成html文件
